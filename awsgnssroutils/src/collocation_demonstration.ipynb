{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b077f0c8",
   "metadata": {},
   "source": [
    "#  Operationalized Rotation-Collocation for Finding Collocated RO and Nadir-scanner Soundings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bfb2fe",
   "metadata": {},
   "source": [
    "This demonstrates how to use the various utilities associated with collocation-finding algorithms, \n",
    "including how to query for occultations, how to define a nadir-scanning radiance instrument, how to \n",
    "find collocations by brute force, how to find collocations by the rotation-collocation method, how to \n",
    "populate sounder data before extracting calibrated measurements, how to extract the collocated nadir-scanner \n",
    "sounding measurements for the found collocations, and how to save collocation data to an output \n",
    "NetCDF file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d599578",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "You will need to set defaults for awsgnssroutils.database and for the EUMETSAT data store. The former is \n",
    "necessary for accessing GNSS radio occultation (RO) data in the AWS Registry of Open Data; the latter for \n",
    "accessing AMSU-A radiance data from the Metop satellites in the EUMETSAT Data Store. \n",
    "\n",
    "### awsgnssroutils.database \n",
    "\n",
    "The awsgnssroutils.database API is designed with efficiency in mind. Toward that end, copies of RO \n",
    "metadata records are stored on the local file system, either by pre-population or as requested in \n",
    "querying the metadata for the existence of RO soundings according to mission, satellite, geolocation, etc. \n",
    "\n",
    "In order to set defaults for awsgnssroutils.database, if you haven't done so already, execute the following \n",
    "commands in a python session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d9c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from awsgnssroutils.database import setdefaults\n",
    "\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "repository_directory = os.path.join( HOME, \"local/rodatabase\" )\n",
    "rodata_root_directory = os.path.join( HOME, \"Data/rodata\" )\n",
    "\n",
    "setdefaults( repository=repository_directory, rodata=rodata_root_directory, version=\"v1.1\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41fe1c3",
   "metadata": {},
   "source": [
    "This code defines an RO metadata \"repository\", where the RO metadata repository should reside on the \n",
    "local file system. These are not the same as the RO data themselves, including profile retrievals: \n",
    "they just record geolocation and other characteristics of the soundings. It also defines \"rodata\", \n",
    "where RO data themselves are downloaded for data analysis. \n",
    "\n",
    "The code above roots both the metadata \"repository\" and the data download directories in the user's home directory. \n",
    "Individual users should feel free to establish the metadata repository and the rodata roots wherever they like. It \n",
    "might be preferable to establish the rodata root on a scratch drive if one is available. There is no need for \n",
    "the rodata directory to be on backed-up or any other guaranteed-storage media. \n",
    "\n",
    "Finally, it is worth the user's time to pre-populate the RO metadata. This step will take several minutes to \n",
    "run now, but it will greatly accelerate all RO database queries in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d645adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsgnssroutils.database import populate\n",
    "populate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a54db06",
   "metadata": {},
   "source": [
    "### Space-Track\n",
    "\n",
    "[Space-Track](http://space-track.com) provides two-line element (TLE) data for most if not all scientific and \n",
    "weather satellites. The rotation-collocation algorithm takes advantage of these TLE data, and access to the data as available at Space-Track is automatic. The user of the rotation-collocation code need only establish an account with Space-Track here. Set the defaults to access Space-Track by declaring your username and password for Space-Track and where you would like for the TLE data to be stored on the local file system. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb7e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from awsgnssroutils.collocation.core.spacetrack import setdefaults\n",
    "\n",
    "HOME = os.path.expanduser( \"~\" )\n",
    "spacetrack_root = os.path.join( HOME, \"Data\", \"spacetrack\" )\n",
    "setdefaults( spacetrack_root, \"sleroy@aer.com\", \"-_J_xx46n-K.Cbn\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06657c26",
   "metadata": {},
   "source": [
    "### EUMETSAT Data Store\n",
    "\n",
    "You will need to obtain an account on the EUMETSAT Data Store in order to access Metop AMSU-A\n",
    "data. You can register for an account at http://eoportal.eumetsat.int/cas/login if you haven't \n",
    "done so already. Once you have obtained an account, you will have to configure your operating \n",
    "Linux/Unix account using the following command: \n",
    "    \n",
    "```\n",
    "% eumdac set-credentials ConsumerKey ConsumerSecret\n",
    "```\n",
    "\n",
    "The ConsumerKey and the ConsumerSecret can be found at https://api.eumetsat.int/api-key/ after \n",
    "you have already set up your account. \n",
    "\n",
    "Next you'll have to define a root for the storage of EUMETSAT Data Store data on the local \n",
    "file system. Do that using the *setdefaults* method in the **eumetsat** module. As for RO data, \n",
    "you should feel free to tweek the code below to root the EUMETSAT Data Store downloads on a \n",
    "scratch disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37563655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from awsgnssroutils.collocation.core.eumetsat import setdefaults\n",
    "\n",
    "HOME = os.path.expanduser( \"~\" )\n",
    "path = os.path.join( HOME, \"Data\", \"eumdac\" )\n",
    "setdefaults( path )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff2227-2609-4ed8-85e4-625d9b937e82",
   "metadata": {},
   "source": [
    "### NASA Earthdata\n",
    "\n",
    "You will need to obtain an account on NASA Earthdata in order to access JPSS data, including \n",
    "ATMS and CrIS data. You can sign up for an account, if you don't already have one, on \n",
    "http://earthdata.nasa.gov. Once you have that account, you must define your Earthdata \n",
    "username and password. Don't worry, all such defaults are protected from all other users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd34a1e-2ab2-4102-8446-6f3f778319be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from awsgnssroutils.collocation.core.nasa_earthdata import setdefaults\n",
    "\n",
    "HOME = os.path.expanduser( \"~\" )\n",
    "path = os.path.join( HOME, \"Data\", \"earthdata\" )\n",
    "setdefaults( path, earthdatalogin=(\"username\",\"password\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a902378",
   "metadata": {},
   "source": [
    "## Demonstration\n",
    "\n",
    "This begins the demonstration of RO and nadir-scanner collocation finding. First, set the parameters \n",
    "that define the scenario: the time period over which you wish to scan for collocations, the RO data processing \n",
    "center from which to download RO data, the collocation spatial and temporal tolerances. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ae4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta \n",
    "\n",
    "#  RO processing center. The choices are \"ucar\", \"romsaf\", and \"jpl\". Only \n",
    "#  \"ucar\" provides cosmic2 and Spire data in addition to Metop data. \n",
    "#  \"romsaf\" does provide Metop RO data. \n",
    "\n",
    "ro_processing_center = \"ucar\"                  # Choice of \"ucar\", \"romsaf\", \"jpl\"\n",
    "\n",
    "#  Time period. Defined as a 2-tuple (or 2-element list) of instances of \n",
    "#  datetime.datetime. Each is interpreted as UTC time. \n",
    "\n",
    "day = datetime( year=2023, month=7, day=5 )    # July 5, 2023\n",
    "nextday = day + timedelta(days=1)\n",
    "datetimerange = ( day, nextday )\n",
    "\n",
    "#  Spatial and temporal tolerances. These are used primarily for the brute \n",
    "#  force collocation algorithm. \n",
    "\n",
    "time_tolerance = 600                           # 10 min/600 sec\n",
    "spatial_tolerance = 150.0e3                    # m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9394014e",
   "metadata": {},
   "source": [
    "Create the portal to the RO metadata database, the Celestrak database, and the \n",
    "EUMETSAT Data Store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad55721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsgnssroutils.database import RODatabaseClient\n",
    "from awsgnssroutils.collocation.core.spacetrack import Spacetrack\n",
    "from awsgnssroutils.collocation.core.eumetsat import EUMETSATDataStore\n",
    "\n",
    "db = RODatabaseClient()\n",
    "st = Spacetrack()\n",
    "eumetsat_data_access = EUMETSATDataStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40caa251",
   "metadata": {},
   "source": [
    "Define the nadir-scanner satellite and instrument. The methods defining the instruments \n",
    "are keys in the *instruments* package. The arguments to the definition call are \n",
    "1. Satellite name\n",
    "2. Approximate radius of orbit\n",
    "3. Maximum scan angle for scanning\n",
    "4. Time between consecutive scans\n",
    "5. Number of footprints in each scan \n",
    "6. Angular spacing in scan angle between neighboring footprints in a scan\n",
    "7. The portal to the EUMETSAT Data Store\n",
    "8.  The portal to the Celestrak repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c21ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsgnssroutils.collocation.instruments import instruments\n",
    "\n",
    "MetopAMSUA = instruments['Metop_AMSUA']['class']\n",
    "MetopB_AMSUA = MetopAMSUA( 'Metop-B', eumetsat_data_access, spacetrack=st )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d794aa",
   "metadata": {},
   "source": [
    "Now query the RO metadata database for occultation soundings. The result is an instance of \n",
    "OccList. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a829df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "print( \"Querying occultation database\" )\n",
    "\n",
    "tbegin = time()\n",
    "occs = db.query( receivers=\"metopb\", datetimerange=[ dt.isoformat() for dt in datetimerange ], \n",
    "                availablefiletypes=f'{ro_processing_center}_refractivityRetrieval', silent=True )\n",
    "tend = time()\n",
    "\n",
    "print( \"  - number found = {:}\".format( occs.size ) )\n",
    "print( \"  - elapsed time = {:10.3f} s\".format( tend-tbegin ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efa916e",
   "metadata": {},
   "source": [
    "Now implement the rotation-collocation algorithm. The temporal and \n",
    "spatial tolerances are only used for internal checking purposes. The last \n",
    "argument in the call to *rotation_collocation* specifies the number of \n",
    "sub-occultations to use for collocation finding. Using just two sub-occultations \n",
    "works for most cases. Only when the temporal tolerance exceeds 30 minutes do \n",
    "more than 2 sub-occultations need to be specified. The number of sub-occultations \n",
    "should correspond to the temporal tolerance divided by 30 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from awsgnssroutils.collocation.core.rotation_collocation import rotation_collocation\n",
    "\n",
    "print( \"Executing rotation-collocation\" )\n",
    "\n",
    "tbegin = time()\n",
    "collocations_rotation = rotation_collocation( MetopB_AMSUA, occs, \n",
    "        time_tolerance, spatial_tolerance, 2 )\n",
    "tend = time()\n",
    "\n",
    "print( \"  - number found = {:}\".format( len( collocations_rotation ) ) )\n",
    "print( \"  - elapsed time = {:10.3f} s\".format( tend-tbegin ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8255bfce",
   "metadata": {},
   "source": [
    "So far we have simply found the number of RO-nadir scanner collocations. We have also \n",
    "stored some information that will help us find the actual data values for the nadir-scanner \n",
    "observations. Before we download those data, however, we first need to populate the Metop-B AMSU-A \n",
    "root with the relevant data files. This is how it's done. Note that downloading from the EUMETSAT \n",
    "Data Store can be a **very** time-consuming operation. We've tried to make this as efficient as \n",
    "possible by first searching the local repository before requesting data downloads from the \n",
    "EUMETSAT Data Store. Hence, the first time you execute this code, it could take many minutes. \n",
    "Subsequent searches will take only a few seconds provided you do not flush the EUMETSAT Data Store \n",
    "local repository (as defined above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab88aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Populating Metop AMSU-A local repository\" )\n",
    "\n",
    "tbegin = time()\n",
    "MetopB_AMSUA.populate( datetimerange )\n",
    "tend = time()\n",
    "\n",
    "print( \"  - elapsed time = {:10.3f} s\".format( tend-tbegin ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a147cd72",
   "metadata": {},
   "source": [
    "Now we extract the nadir-scanner calibrated (level 1B) observations for the collocations. The data are \n",
    "stored as xarray Datasets. Feel free to examine *cdata* when done. It contains the *occid* identifier \n",
    "for the collocation --- actually, it identifies the occultation --- and the occultation and sounder data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32df082",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Extracting collocation data\" )\n",
    "tbegin = time()\n",
    "for collocation in collocations_rotation: \n",
    "    occid = collocation.get_data( ro_processing_center )\n",
    "tend = time()\n",
    "print( \"  - elapsed time = {:10.3f} s\".format( tend-tbegin ) )\n",
    "cdata = collocations_rotation[0].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d02d9e",
   "metadata": {},
   "source": [
    "Finally, we write the collocation data to an output NetCDF file. The collocation data \n",
    "are stored in a group structure. At the highest level, each group corresponds to a \n",
    "collocation. Two sub-groups are contained in each collocation group: one that contains \n",
    "occultation data, and the other contains nadir-scanner data. All are annoted with attributes\n",
    "as appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027aebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"collocations.nc\"\n",
    "tbegin = time()\n",
    "print( f\"Writing to output file {file}\" )\n",
    "collocations_rotation.write_to_netcdf( file )\n",
    "tend = time()\n",
    "print( \"  - elapsed time = {:10.3f} s\".format( tend-tbegin ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eab692a",
   "metadata": {},
   "source": [
    "The following code illustrates how to use the brute force collocation finding algorithm. It follows up by \n",
    "evaluating the confusion matrix analyzing the performance of the rotation-collocation algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8fc04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsgnssroutils.collocation.core.brute_force import brute_force\n",
    "from awsgnssroutils.collocation.core.collocation import collocation_confusion\n",
    "\n",
    "print( \"Executing brute force\" )\n",
    "tbegin = time()\n",
    "collocations_sorted = brute_force( MetopB_AMSUA, occs, time_tolerance, spatial_tolerance, progressbar=False )\n",
    "tend = time()\n",
    "print( \"  - elapsed time = {:10.3f} s\".format( tend-tbegin ) )\n",
    "\n",
    "#  Confusion matrix. \n",
    "\n",
    "confusion = collocation_confusion( occs, collocations_sorted, collocations_rotation )\n",
    "\n",
    "print( '\\nConfusion matrix\\n================' )\n",
    "print( '{:12s}{:^12s}{:^12s}'.format( \"\", \"Positive\", \"Negative\" ) )\n",
    "print( '{:12s}{:^12d}{:^12d}'.format( \"True\", confusion['true_positive'], confusion['true_negative'] ) )\n",
    "print( '{:12s}{:^12d}{:^12d}'.format( \"False\", confusion['false_positive'], confusion['false_negative'] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eee614",
   "metadata": {},
   "source": [
    "## ATMS and the Earthdata DAAC\n",
    "\n",
    "Demonstrate the use of the NASAEarthdata class to access the NASA Earthdata \n",
    "DAAC portal (and earthaccess API). Also use the ATMS instrument class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca4ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Access to RO data, Celestrak TLEs, and NASA Earthdata DAAC\n",
    "\n",
    "from awsgnssroutils.database import RODatabaseClient\n",
    "from awsgnssroutils.collocation.core.spacetrack import Spacetrack\n",
    "from awsgnssroutils.collocation.core.nasa_earthdata import NASAEarthdata\n",
    "\n",
    "db = RODatabaseClient()\n",
    "st = Spacetrack()\n",
    "nasa_earthdata_access = NASAEarthdata()\n",
    "\n",
    "#  Define JPSS-1 ATMS instrument. \n",
    "\n",
    "from awsgnssroutils.collocation.instruments import instruments\n",
    "\n",
    "JPSS1_ATMS = instruments['JPSS_ATMS']['class']( \"JPSS-1\", nasa_earthdata_access, spacetrack=st )\n",
    "\n",
    "#  Time interval for collocation finding. \n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "day = datetime( year=2023, month=6, day=5 )\n",
    "nextday = day + timedelta(days=1)\n",
    "datetimerange = ( day, nextday )\n",
    "\n",
    "#  Collocation tolerances. \n",
    "\n",
    "time_tolerance = 600                           # 10 min/600 sec\n",
    "spatial_tolerance = 150.0e3                    # m\n",
    "\n",
    "#  Get occultation geolocations. \n",
    "\n",
    "ro_processing_center = \"ucar\"\n",
    "ro_mission = \"cosmic2\"\n",
    "\n",
    "from time import time\n",
    "\n",
    "print( \"Querying occultation database\" )\n",
    "\n",
    "tbegin = time()\n",
    "occs = db.query( missions=ro_mission, datetimerange=[ dt.isoformat() for dt in datetimerange ], \n",
    "                availablefiletypes=f'{ro_processing_center}_refractivityRetrieval', silent=True )\n",
    "tend = time()\n",
    "\n",
    "print( \"  - number found = {:}\".format( occs.size ) )\n",
    "print( \"  - elapsed time = {:10.3f} s\".format( tend-tbegin ) )\n",
    "\n",
    "#  Exercise rotation-collocation. \n",
    "\n",
    "from awsgnssroutils.collocation.core.rotation_collocation import rotation_collocation\n",
    "\n",
    "print( \"Executing rotation-collocation\" )\n",
    "\n",
    "tbegin = time()\n",
    "collocations_rotation = rotation_collocation( JPSS1_ATMS, occs, \n",
    "        time_tolerance, spatial_tolerance, 2 )\n",
    "tend = time()\n",
    "\n",
    "print( \"  - number found = {:}\".format( len( collocations_rotation ) ) )\n",
    "print( \"  - elapsed time = {:10.3f} s\".format( tend-tbegin ) )\n",
    "\n",
    "#  Populate ATMS data. \n",
    "\n",
    "tbegin = time()\n",
    "JPSS1_ATMS.populate( datetimerange )\n",
    "tend = time()\n",
    "\n",
    "print( \"  - elapsed time = {:10.3f} s\".format( tend-tbegin ) )\n",
    "\n",
    "#  Extract data. \n",
    "\n",
    "print( \"Extracting collocation data\" )\n",
    "tbegin = time()\n",
    "for collocation in collocations_rotation: \n",
    "    occid = collocation.get_data( ro_processing_center )\n",
    "tend = time()\n",
    "print( \"  - elapsed time = {:10.3f} s\".format( tend-tbegin ) )\n",
    "cdata = collocations_rotation[0].data\n",
    "\n",
    "#  Save to output file. \n",
    "\n",
    "file = \"cosmic2_collocations.nc\"\n",
    "tbegin = time()\n",
    "print( f\"Writing to output file {file}\" )\n",
    "collocations_rotation.write_to_netcdf( file )\n",
    "tend = time()\n",
    "print( \"  - elapsed time = {:10.3f} s\".format( tend-tbegin ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d3d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
